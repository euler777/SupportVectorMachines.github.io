# Support Vector Machines

So far we have introduced 3 supervised classification approaches in Chapter 2 (K- nearest neighbors, logistic regression and discriminant anal- ysis) and 1 in Chapter 6 (classification tree). In this chapter, we discuss the support vector machines (SVMs), an approach for classification that was de- veloped in the computer science community in the 1990s and that has grown in popularity since then. Compared to the 4 methods that we have introduced in Chapter 2 and 6, SVMs look for
estimating the decision boundary functions by setting up an optimization problem. When the shape of the boundaries (linear? polynomial? exponential?) are known, SVMs have more advantages. For instance, it is more general and it performs much better in most cases when dealing with a variety of settings of modern data.

Main goal: To know the 3 SVMs approaches: the maximal margin classifi- er (hyperplane), the support vector classifier (soft margin), and the support vector machine with linear, polynomial and radial kernels.
